---
title: "$t$ test a special case of regression? Strange but true ..."
author: "Peter Geelan-Small - Stats Central, UNSW"
date: "17/06/2021"
output:
  xaringan::moon_reader:
    css: [default, metropolis, metropolis-fonts]
    lib_dir: libs
    self_contained: false
    nature:
      highlightStyle: github
      countIncrementalSlides: false
      beforeInit: "macros.js"
---


```{r setup, include = F}

knitr::opts_chunk$set(echo = F, fig.align = "center", 
                      fig.asp = 1,
                      echo = F, message = F, warning = F)

```



```{r xaringan-logo, echo = F}

library(xaringanExtra)

use_logo(
  image_url = "StatsCentralLogo_rmd.png",
  width = "110px",
  height = "128px",
  position = css_position(bottom = "-2.5em", left = "1em"),
  link_url = NULL,
  exclude_class = c("title-slide", "inverse", "hide_logo")
)

```



```{r echo = F, message = F}

library(RColorBrewer)
library(wordcloud)
library(tidyverse)
library(ggpubr)
library(GGally)
library(plotly)
library(reshape2)  ## For "acast"
library(png)
library(kableExtra)
library(emmeans)

```


<style type="text/css">
.remark-slide-content {
  font-size: 28px;
  padding: 1em 1em 1em 1em;
}
</style>



# Background

Why think about link between $t$ test and regression?

```{r}

words_df <- read.csv("../data/stats_tests.csv", header = F)

{{wordcloud(words = words_df[ , 1], freq = words_df[ , 2],
          colors = brewer.pal(6, "Dark2"),
          random.color = T,
          scale = c(3, 1), rot.per = 1/4)}}

```


---

# Statistical modelling

- Sensible modelling starts with *research questions* and *statistical analysis plan* written at start of study
- Not so useful to ask, "What statistical tests do I need to use?"
    - "Flowchart" approach - hides unity behind "different" methods
- Better to ask first, "How can I use the variables in my data to answer my research questions?"
    - Focus on relationships between variables
    - Helps you see not so many "different" methods after all!

---

# Outline

- Data for examples
    - Randomised controlled trial
    - Effect of hormones on preventing heart disease events among older women (Heart and Estrogen/progestin Replacement Study (HERS) (Hulley et al. 1998)
    - Data available through Vittinghoff (2012)
- Example models
    - Regression to $t$ tests
    - Model equations
- What makes a linear model *linear*?
- Why there might be fewer statistical methods than you think!


---

# Outline

## Note

- Modelling here does not follow a sensible statistical analysis plan
- Models shown are only examples for today's topic
- Response variables we're looking at are continuous
    - For these continuous response variables, model with normal distribution assumption makes sense
- Assumptions for all models should be checked - only first one done here



---

# Data

Data has 37 variables from 2,763 subjects

```{r}

hers <- read.csv("../data/hersdata_ch3.csv")

## There are blanks in the data. Convert them to NAs

hers[hers == ""] <- NA

## Convert all character variables to factors

hers <- 
  hers %>%
  mutate(across(where(is.character), as.factor))

hers %>%
  select(HT, age, BMI, drinkany, exercise, diabetes, glucose) %>%
  str()

```


- Data for non-diabetics only will be used



```{r}

######
###### Set up the data needed here
######

hers_no_diab <- 
  hers %>%
  filter(diabetes == "no")

```



```{r eval = F}

## Check for NAs

summary(hers_no_diab)

```



```{r}

## Remove rows with BMI values of NA

hers_no_diab <-
  hers_no_diab %>%
  filter(is.na(BMI) == F)

## Remove data point with glucose < 60 to make plots clearer

hers_no_diab <-
  hers_no_diab %>%
  filter(glucose > 60)

```

---

# Simple linear regression

*Can BMI (body mass index) predict baseline glucose level?*

.pull-left[

- Response: glucose - continuous
- Predictor: BMI - continuous
- Model assuming normal distribution
- Straight-line model

*Model equation*

$$\small Y = \beta_0 + \beta_1 X_1$$

]

.pull-right[

```{r fig.width = 5, fig.height = 5}

ggplot(hers_no_diab, aes(x = BMI, y = glucose)) +
  geom_point(colour = "#884422", size = 1) +
  theme_bw()

```

]


---

# Simple linear regression

```{r}

glu.lm1 <- lm(glucose ~ BMI, data = hers_no_diab)


## Check quadratic term

#hers_no_diab$BMI_sq <- hers_no_diab$BMI^2

#glu.lm11 <- lm(glucose ~ BMI + BMI_sq, data = hers_no_diab)

#anova(glu.lm1, glu.lm11) ## No diff. between models

```


*Assumptions:* Check constant variance and normal distribution. OK!


```{r}

res.glu1 <- data.frame(res = residuals(glu.lm1))

res.fit.glu1 <- data.frame(res = res.glu1$res,
                           fit = fitted(glu.lm1))

```


.pull-left[

```{r}

ggplot(res.fit.glu1, aes(x = fit, y = res)) +
  geom_point(size = 1) +
  geom_hline(yintercept = 0, colour = "blue") +
  labs(x = "Fitted values", y = "Residuals") +
  theme_bw()

```

]


.pull-right[

```{r}

ggplot(res.glu1, aes(sample = res)) +
  stat_qq() +
  stat_qq_line() +
  theme_bw()

```

]


```{r fig.width = 6, fig.height = 6, eval = F}

res.glu1 <- data.frame(res = residuals(glu.lm1))

res.fit.glu1 <- data.frame(res = res.glu1$res,
                           fit = fitted(glu.lm1))

glu1_p1 <- ggplot(res.fit.glu1, aes(x = fit, y = res)) +
  geom_point() +
  geom_hline(yintercept = 0, colour = "blue") +
  theme_bw()
  
glu1_p2 <- ggplot(res.glu1, aes(sample = res)) +
  stat_qq() +
  stat_qq_line() +
  theme_bw()

ggarrange(glu1_p1, glu1_p2)

#par(mfrow = c(1, 2))
#{{plot(glu.lm1, which = 1)}}
#{{plot(glu.lm1, which = 2)}}
#par(mfrow = c(1, 1))
    
```


---

# Simple linear regression  
  

```{r}

round(summary(glu.lm1)$coef, digits = 4)

```

BMI is a useful predictor but model not very good (low $R^2$).

*Fitted model*

$$\small \mathrm{glucose} = 83.3 + 0.48 \, \mathrm{BMI}$$

---

# Simple linear regression

```{r}

nd <- data.frame(BMI = 40)

pred_bmi_40 <- predict(glu.lm1, newdata = nd)

```


.pull-left[

What can we do with our fitted model?

-  Predict glucose from BMI

- If BMI = 40, what is the predicted mean glucose level?

$$\small \mathrm{glucose} =  83.3 + 0.48 \times 40 = 103$$
]


.pull-right[

```{r message = F}

pred_df1 <- data.frame(x1 = 40, y1 = 65, 
                       x2 = 40, y2 = pred_bmi_40)

pred_df2 <- data.frame(x1 = 14, y1 = 102.7, 
                       x2 = 40, y2 = pred_bmi_40)

glu1_p3 <-
  ggplot(hers_no_diab, aes(x = BMI, y = glucose)) +
  geom_point() +
  geom_smooth(method = "lm", se = F) +
  scale_x_continuous(expand = c(0.01, 0.05)) +
  scale_y_continuous(expand = c(0.01, 0.05)) +
  theme_bw()

glu1_p4 <- glu1_p3 + 
  geom_segment(aes(x = x1, y = y1, xend = x2, yend = y2), 
               data = pred_df1, linetype = "dashed", 
               colour = "red") +
  geom_segment(aes(x = x1, y = y1, xend = x2, yend = y2), 
               data = pred_df2, linetype = "dashed", 
               colour = "red")

suppressMessages(print(glu1_p4))
  
```

]

---

# What is "linear"?

- "Linear" means straight line. No argument!
- Linear regression model means right-hand side of equation is a linear combination of predictors (i.e. pattern is: *parameter1* $\times$ *predictor1* + *parameter2* $\times$ *predictor2* + ... )

- Both these are linear models:

$$\small \mathrm{glucose} =  \beta_0 + \beta_1 \, \mathrm{BMI}$$
$$\small \mathrm{glucose} =  \beta_0 + \beta_1 \, \mathrm{BMI}+ \beta_2 \, \mathrm{BMI}^2$$

- This is not a linear model:

$$\small \mathrm{glucose} =  \beta_0 \, \mathrm{BMI}^{\, \beta_1}$$


---

# Multivariable linear regression

*Is age a useful predictor of glucose level as well as BMI?*


```{r eval = F, message = F}

hers_no_diab %>%
  select(age, BMI, glucose) %>%
  ggpairs() +
  theme_bw()

```


```{r}

hers_no_diab %>%
  select(age, BMI, glucose) %>%
  pairs()

```


---

# Multivariable linear regression

- Add *age* (continuous variable) to model

*Model equation*

$$\small \mathrm{glucose} = \beta_0 + \beta_1 \, \mathrm{BMI} + \beta_2 \, \mathrm{age}$$


```{r}

glu.lm2 <- lm(glucose ~ BMI + age, data = hers_no_diab)

round(summary(glu.lm2)$coef, digits = 4)

```


*Fitted model*

$$\small \mathrm{glucose} = 79.2 + 0.50 \, \mathrm{BMI} + 0.06 \, \mathrm{age}$$

---

# Multivariable linear regression

*Fitted model*

$$\small \mathrm{glucose} = 79.2 + 0.06 \, \mathrm{age} + 0.50 \, \mathrm{BMI}$$

-  Person who is 60 years old with BMI of 40: glucose = 102

$$\small \mathrm{glucose} = 79.2 + 0.06 \times 60 + 0.50 \times 40 = 102$$


---

# Multivariable linear regression

*Fitted model with data*

```{r}

xx <- seq(min(hers_no_diab$age), max(hers_no_diab$age),
          length.out = 100)

yy <- seq(min(hers_no_diab$BMI), max(hers_no_diab$BMI),
          length.out = 100)

surf_df <- expand.grid(age = xx, BMI = yy)

surf_df$glucose <- predict.lm(glu.lm2, newdata = surf_df)

## Rearrange x, y and z values into a matrix with "acast" 
##   from "reshape2" (i.e. recast it as an array)

surf_mat <- acast(surf_df, BMI ~ age, value.var = "glucose") 
## y ~ x

```



```{r}

## Construct plot of data points

p_glu_age_bmi <- plot_ly(hers_no_diab,
  x = ~ age,
  y = ~ BMI,
  z = ~ glucose,
  type = "scatter3d",
  mode = "markers",
  size = 1, opacity = 0.3)

## Add fitted model surface

p_glu_age_bmi <- add_trace(
  p = p_glu_age_bmi,
  z = surf_mat,
  x = xx,
  y = yy,
  type = "surface")

p_glu_age_bmi

```


---

# Multivariable linear regression

*Does exercise affect glucose level while adjusting for BMI?* (ANCOVA)


```{r}

## Make this graph and then put "eval = F"!

glu3_p1 <- ggplot(hers_no_diab, 
                  aes(x = BMI, y = glucose, 
                      colour = exercise)) +
  geom_point(size = 1) +
  theme_bw()

#suppressMessages(print(glu3_p1))


png(filename = "glu3_p1.png",
    width = 500, height = 350)

print(glu3_p1)

dev.off()

```


.center[![:scale 75%](glu3_p1.png)]


---

# Multivariable linear regression

How do BMI and exercise fit together in their effect on glucose?

```{r eval = F}

## Make this graph and then put "eval = F"!

bmi <- seq(from = 15, to = 50, length.out = 70)


glu_comm <- 83 + 0.5 * bmi

glu_para_ex_n <- 86 + 0.5 * bmi

glu_para_ex_y <- 82 + 0.5 * bmi

glu_sep_ex_n <- 84 + 0.7 * bmi

glu_sep_ex_y <- 83 + 0.4 * bmi


df_comm <- data.frame(BMI = bmi, glucose = glu_comm)

df_para <- data.frame(BMI = c(bmi, bmi), 
                      glucose = c(glu_para_ex_n, glu_para_ex_y),
                      exercise = rep(c("no", "yes"), each = 70))

df_para$exercise <- factor(df_para$exercise)

df_sep <- data.frame(BMI = c(bmi, bmi), 
                      glucose = c(glu_sep_ex_n, glu_sep_ex_y),
                      exercise = rep(c("no", "yes"), each = 70))

df_sep$exercise <- factor(df_sep$exercise)

p_comm <- 
  ggplot(df_comm, aes(x = BMI, y = glucose)) +
  geom_line(colour = "#bb8844", size = 1.5) +
  ylim(85, 120) +
  ggtitle("Common line") +
  theme_bw() +
  theme(plot.title = element_text(size = 10))

p_para <- 
  ggplot(df_para, aes(x = BMI, y = glucose, colour = exercise)) +
  geom_line(size = 1.5) +
  ylim(85, 120) +
  ggtitle("Parallel lines") +
  theme_bw() +
  theme(plot.title = element_text(size = 10)) +
  theme(legend.position = "none")

p_sep <- 
  ggplot(df_sep, aes(x = BMI, y = glucose, colour = exercise)) +
  geom_line(size = 1.5) +
  ylim(85, 120) +
  ggtitle("Separate intercepts & slopes") +
  theme_bw() +
  theme(plot.title = element_text(size = 10))

png(filename = "p_all_reg.png",
    width = 500, height = 350)

ggarrange(p_comm, p_para, p_sep, ncol = 3, common.legend = T)

dev.off()

```


.center[![:scale 75%](p_all_reg.png)]

---

# Multivariable linear regression

*Model equation (parallel lines) - two predictor variables*

-  BMI - continuous
-  exercise - categorical (no/yes coded as 0/1)
    
$$\small \mathrm{glucose} = \beta_0 + \beta_1 \, \mathrm{BMI} + \beta_2 \, \mathrm{exer}_{\mathrm{yes}}$$
For exercise = no (i.e. 0): $$\small \mathrm{glucose} = \beta_0 + \beta_1 \, \mathrm{BMI}$$

For exercise = yes (i.e. 1):$$\small \mathrm{glucose} = \beta_0 + \beta_1 \, \mathrm{BMI} + \beta_2 \;\;\; \mathrm{or} \;\;\; \mathrm{glucose} = (\beta_0 + \beta_2) + \beta_1 \, \mathrm{BMI}$$

---

# Multivariable linear regression


```{r}

glu.lm3 <- lm(glucose ~ BMI + exercise, data = hers_no_diab)

round(summary(glu.lm3)$coef[ , -c(4:5)], digits = 3)

```

*Fitted model*

$$\small \mathrm{glucose} = 84.0 + 0.47 \, \mathrm{BMI} -0.87 \, \mathrm{exer}_{\mathrm{yes}}$$

For exercise = no (i.e. 0): $$\small \mathrm{glucose} = 84.0 + 0.47 \, \mathrm{BMI}$$

For exercise = yes (i.e. 1):$$\small \mathrm{glucose} = 84.02 + 0.47 \, \mathrm{BMI} - 0.87 \;\;\; \mathrm{or} \;\;\; \mathrm{glucose} = 83.2 + 0.47 \, \mathrm{BMI}$$


---

# Multivariable linear regression

*Fitted model with data*

```{r}

hers_no_diab$pred3 <- predict(glu.lm3)

ggplot(hers_no_diab, aes(x = BMI, y = glucose, 
                         colour = exercise)) +
  geom_point(size = 1) + 
  geom_line(aes(y = pred3), size = 1) +
  theme_bw()

```


---

# Predictor: categorical, two groups - *t* test

*Does exercise alone affect glucose level?* (*t* test)


```{r}

ggplot(hers_no_diab, aes(x = exercise, y = glucose)) +
  geom_boxplot(outlier.shape = NA) +  
  # avoid plotting outliers twice
  geom_jitter(position = position_jitter(width = 0.3, height = 0),
              alpha = 0.3, colour = "#884422") +
  theme_bw()

```


---

# Predictor: categorical, two groups - *t* test


-  Response: glucose
-  Predictor: exercise - categorical (no/yes coded as 0/1)

*Model equation (two parameters)*

$$\small \mathrm{glucose} = \beta_0 + \beta_1 \, \mathrm{exer}_{\mathrm{yes}}$$

```{r}

glu.lm4 <- lm(glucose ~ exercise, data = hers_no_diab)

round(summary(glu.lm4)$coef[ , -c(4:5)], digits = 3)

```

For exercise = no: $\;\;$ Est. mean glucose = 97.4

For exercise = yes: $\;$ Est. mean glucose = 97.37 - 1.64 = 95.7

---

# Predictor: categorical, two groups - *t* test


```{r}

t.test(glucose ~ exercise, data = hers_no_diab, var.equal = T)

```

$t$ test is just a linear model

- Special case - one categorical predictor variable with two groups

---

# What's missing? ANOVA!

*Does a subject's physical activity level compared to other women of similar age help to explain glucose level?*


```{r}

## Rename and reorder levels of "physact"

#levels(hers_no_diab$physact)

## Levels in orig. data are:

# [1] "about as active"      "much less active"    
# [3] "much more active"     "somewhat less active"
# [5] "somewhat more active"

## Rename

hers_no_diab$physactive <- factor(
  hers_no_diab$physact, 
  labels = c("equal", "much_less", "much_more", "less", "more")
  )

#data.frame(orig = hers_no_diab$physact[1:20],
#           new = hers_no_diab$physactive[1:20])

## Re-order

hers_no_diab$physactive <- factor(
  hers_no_diab$physactive, 
  levels = c("much_less", "less", "equal", "more", "much_more"))

#levels(hers_no_diab$physactive)
       
```



```{r}

ggplot(hers_no_diab, aes(x = physactive, y = glucose)) +
  geom_boxplot(outlier.shape = NA) +  
  # avoid plotting outliers twice
  geom_jitter(position = position_jitter(width = 0.3, height = 0),
              alpha = 0.3, colour = "#884422") +
  theme_bw()

```


---

# What's missing? ANOVA!


-  Response: glucose
-  Predictor: physical activity - categorical (5 categories)

*Model equation (five parameters, four variables)*

$$\beta_0 \;\;\; \mathrm{much\_less}$$
$$X_\mathrm{less} \;\;\; \mathrm{less - coded \; as \; 0/1}$$

$$X_\mathrm{eq} \;\;\; \mathrm{equal - coded \; as \; 0/1}$$
$$\mathrm{etc.}$$

$$\small \mathrm{glucose} = \beta_0 + \beta_1 \, X_\mathrm{less} + \beta_2 \, X_\mathrm{eq} + \beta_3 \, X_\mathrm{more} + \beta_4 \, X_\mathrm{much\_more}$$


---

# What's missing? ANOVA!

Software turns categories of *physactive* into five 0/1 variables

```{r}

glu.lm5 <- lm(glucose ~ physactive, data = hers_no_diab)

df5 <- data.frame(model.matrix(glu.lm5)[1:6, ])
names(df5) <- c("Intercept", "less", "equal", "more", "much_more")

df5 <- data.frame(physactive = hers_no_diab$physactive[1:6], df5)

knitr::kable(df5, format = "html")
             
```


---

# What's missing? ANOVA!


```{r}

## Repeated model call

glu.lm5 <- lm(glucose ~ physactive, data = hers_no_diab)

round(summary(glu.lm5)$coef[ , -c(4:5)], digits = 3)

```


*Fitted model*

$$\small \mathrm{glucose} = 98.42 - 0.86 \, X_\mathrm{less} - 1.21 \, X_\mathrm{eq} - 2.36 \, X_\mathrm{more} - 3.28 \, X_\mathrm{much\_more}$$


---

# What's missing? ANOVA!

*Fitted model*

$$\small \mathrm{glucose} = 98.42 - 0.86 \, X_\mathrm{less} - 1.21 \, X_\mathrm{eq} - 2.36 \, X_\mathrm{more} - 3.28 \, X_\mathrm{much\_more}$$


```{r}

glu5.emm <- as.data.frame(emmeans(glu.lm5, ~ physactive))

glu5.means <- round(glu5.emm$emmean, digits = 1)


Activity <- c("much_less", "less", "equal", "more", "much_more")

Mean_glucose <- c("98.42", "98.42 - 0.86", "98.42 - 1.21",
                  "98.42 - 2.36", "98.42 - 3.28")

Fitted_mean <- glu5.means

glu5_out <- data.frame(Activity, Mean_glucose, Fitted_mean)

names(glu5_out) <- c("Activity", "Mean calc.", "Fitted mean")

knitr::kable(glu5_out, format = "html")

```


---

# Linear models


**They're all the same type of model - a linear model!**


```{r}

{{wordcloud(words = words_df[ , 1], freq = words_df[ , 2],
          colors = brewer.pal(6, "Dark2"),
          random.color = T,
          scale = c(3, 1), rot.per = 1/4)}}

```


---


# References

Hulley, S. et al, 1998, Randomized trial of estrogen plus progestin for secondary prevention of coronary heart disease in postmenopausal women, *Journal of the American Medical Association* 280(7) 605-613

Vittinghoff, E., 2012, *Regression Methods in Biostatistics*, Springer, 2nd ed. (https://regression.ucsf.edu)